{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T09:20:43.626605Z",
     "start_time": "2019-01-26T09:20:43.622077Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-csv_2.10:1.3.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T09:21:01.107471Z",
     "start_time": "2019-01-26T09:20:45.606579Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T09:21:03.721001Z",
     "start_time": "2019-01-26T09:21:03.714406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xiaofeiwu/jcloud/assets/langs/workspace/spark/workspace/notebook\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T09:21:17.862100Z",
     "start_time": "2019-01-26T09:21:08.148770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "|_c0|speed|dist|\n",
      "+---+-----+----+\n",
      "|  1|    4|   2|\n",
      "|  2|    4|  10|\n",
      "|  3|    7|   4|\n",
      "|  4|    7|  22|\n",
      "|  5|    8|  16|\n",
      "|  6|    9|  10|\n",
      "|  7|   10|  18|\n",
      "|  8|   10|  26|\n",
      "|  9|   10|  34|\n",
      "| 10|   11|  17|\n",
      "| 11|   11|  28|\n",
      "| 12|   12|  14|\n",
      "| 13|   12|  20|\n",
      "| 14|   12|  24|\n",
      "| 15|   12|  28|\n",
      "| 16|   13|  26|\n",
      "| 17|   13|  34|\n",
      "| 18|   13|  34|\n",
      "| 19|   13|  46|\n",
      "| 20|   14|  26|\n",
      "+---+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "file=\"../data/cars.csv\"\n",
    "sqlContext = SQLContext(sc)\n",
    "# df = sqlContext.load(source=\"com.databricks.spark.csv\", header='true', inferSchema='true', path=file)\n",
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true').load(file)\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
