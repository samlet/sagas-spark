{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T13:17:03.226636Z",
     "start_time": "2019-01-27T13:16:56.941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@768a88b7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@768a88b7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// $example on$\n",
    "import org.apache.spark.ml.linalg.{Vector, Vectors}\n",
    "import org.apache.spark.ml.stat.Summarizer\n",
    "// $example off$\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder\n",
    "  .appName(\"SummarizerExample\")\n",
    "  .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "import Summarizer._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Summarizer 计算输入数据框的矢量列的均值和方差，包括和不包含权重列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T13:17:19.538813Z",
     "start_time": "2019-01-27T13:17:06.856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with weight: mean = [3.333333333333333,5.0,6.333333333333333], variance = [2.0,4.5,2.0]\n",
      "without weight: mean = [3.0,4.5,6.0], sum = [2.0,4.5,2.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data = List(([2.0,3.0,5.0],1.0), ([4.0,6.0,7.0],2.0))\n",
       "df = [features: vector, weight: double]\n",
       "meanVal = [3.333333333333333,5.0,6.333333333333333]\n",
       "varianceVal = [2.0,4.5,2.0]\n",
       "meanVal2 = [3.0,4.5,6.0]\n",
       "varianceVal2 = [2.0,4.5,2.0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2.0,4.5,2.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.linalg.{Vector, Vectors}\n",
    "import org.apache.spark.ml.stat.Summarizer\n",
    "\n",
    "val data = Seq(\n",
    "  (Vectors.dense(2.0, 3.0, 5.0), 1.0),\n",
    "  (Vectors.dense(4.0, 6.0, 7.0), 2.0)\n",
    ")\n",
    "\n",
    "val df = data.toDF(\"features\", \"weight\")\n",
    "\n",
    "val (meanVal, varianceVal) = df.select(metrics(\"mean\", \"variance\")\n",
    "  .summary($\"features\", $\"weight\").as(\"summary\"))\n",
    "  .select(\"summary.mean\", \"summary.variance\")\n",
    "  .as[(Vector, Vector)].first()\n",
    "\n",
    "println(s\"with weight: mean = ${meanVal}, variance = ${varianceVal}\")\n",
    "\n",
    "val (meanVal2, varianceVal2) = df.select(mean($\"features\"), variance($\"features\"))\n",
    "  .as[(Vector, Vector)].first()\n",
    "\n",
    "println(s\"without weight: mean = ${meanVal2}, sum = ${varianceVal2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⊕ [Spark求统计量的两种方法 - Thinkgamer博客 - CSDN博客](https://blog.csdn.net/Gamer_gyt/article/details/79253420)\n",
    "\n",
    "主要区别在于dataframe得到的是标准差，而使用mllib得到的统计值中是方差，但这并不矛盾，两者可以相互转化得到。\n",
    "\n",
    "当然如果要求四分位数，可以转化成df，使用sql语句进行查询\n",
    "\n",
    "Select PERCENTILE(col,<0.25,0.75>) from tableName;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T13:23:45.891172Z",
     "start_time": "2019-01-27T13:23:39.692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+----+----------+\n",
      "|age|chinese|english|math|      name|\n",
      "+---+-------+-------+----+----------+\n",
      "| 23|     78|     95|  78|thinkgamer|\n",
      "| 25|     88|     93|  95|     think|\n",
      "| 24|     68|     88|  93|     gamer|\n",
      "+---+-------+-------+----+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [age: bigint, chinese: bigint ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[summary: string, age: string ... 4 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.storage._\n",
    "// persist(StorageLevel.MEMORY_AND_DISK) 当内存不够时cache到磁盘里\n",
    "val df = spark.read.json(\"../../data/example.json\").persist(StorageLevel.MEMORY_AND_DISK)\n",
    "df.show()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T13:27:35.134263Z",
     "start_time": "2019-01-27T13:27:34.385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|summary| age|\n",
      "+-------+----+\n",
      "|  count|   3|\n",
      "|   mean|24.0|\n",
      "| stddev| 1.0|\n",
      "|    min|  23|\n",
      "|    max|  25|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"age\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
